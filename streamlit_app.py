from pathlib import Path
import os

BASE_DIR = Path(__file__).resolve().parent
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(BASE_DIR / "rate-sheet-sql-465312-20bf767d91f2.json")

import streamlit as st
import pandas as pd
import numpy as np
from itertools import product
from bigquery_utils import get_cleaned_tables, get_bigquery_client

# Set up credentials and BigQuery
PROJECT_ID = "rate-sheet-sql-465312"
DATASET_NAME = "ratesheet_processing_dataset"

st.set_page_config(page_title="Rate Sheet Generator", layout="wide")
st.title("ğŸ“¦ Freight Quote Generator")

# Get BigQuery client and tables
@st.cache_resource
def get_tables_and_client():
    client = get_bigquery_client()
    tables = get_cleaned_tables(DATASET_NAME)
    return client, tables

client, table_names = get_tables_and_client()

st.write("âœ… Found the following rate tables in BigQuery:")
st.write(table_names)

# Table selection
selected_table = st.selectbox("Select a Rate Table", table_names)

@st.cache_data(show_spinner=False)
def load_table(table_name):
    query = f"SELECT * FROM `{PROJECT_ID}.{DATASET_NAME}.{table_name}`"
    return client.query(query).to_dataframe()

if selected_table:
    df = load_table(selected_table)
    df["POL"] = df["POL"].astype(str).str.strip()
    df["Destination"] = df["Destination"].astype(str).str.strip()
    df["Carrier"] = df["Carrier"].astype(str).str.strip()

    st.write(f"ğŸ“Š Columns in `{selected_table}`:")
    st.write(df.columns.tolist())

    # Ensure necessary columns exist
    for col in ["COMM", "COMM_DETAILS"]:
        if col not in df.columns:
            df[col] = np.nan
    columns_needed = ["POL", "Destination", "Effective_Date", "Expiring_Date", "T_T_TO_POD", "Carrier", "GP20", "GP40", "COMM", "COMM_DETAILS"]
    existing_columns = [col for col in columns_needed if col in df.columns]
    df = df[existing_columns]

    st.write(f"ğŸ“Š Showing data from {selected_table}:")
    st.write(df)

    # Sidebar UI
    st.sidebar.header("ğŸ”§ Filter Options")
    table_type = st.sidebar.radio("Table Type", ["Port to Port", "Port to Door"])

# ç¤ºä¾‹æ•°æ®
carrier_options = [
    "WANHAI", "SMLM", "YML", "MSC", "OOCL", "ONE", "EMC", "COSCO", 
    "HMM", "HPL", "CMA", "ZIM", "SLS", "TSL", "HEDE", "MATS"
]

origin_ports = [
    'SHENZHEN, GUANGDONG', 'JIUJIANG, GUANGDONG', 'HONG KONG', 'ZHUHAI, GUANGDONG', 
    'SHANGHAI', 'HUANGPU, GUANGDONG', 'XIAMEN, FUJIAN', 'FUZHOU, FUJIAN', 'ZHENJIANG, JIANGSU', 'ZHAPU, ZHEJIANG', 
    'ZHANGJIAGANG, JIANGSU', 'YUEYANG, HUNAN', 'YICHANG, HUBEI', 'YANGZHOU, JIANGSU', 'WUHAN, HUBEI', 'NINGBO, ZHEJIANG', 
    'NANTONG, JIANGSU', 'NANJING, JIANGSU', 'NANCHANG, JIANGXI', 'CHANGZHOU, JIANGSU', 'ANQING, ANHUI', 'XINGANG, TIANJIN', 
    'DALIAN, LIAONING', 'YOKOHAMA, JAPAN', 'VUNG TAU, VIETNAM', 'VISAKHAPATNAM, INDIA', 'TUTICORIN, INDIA', 'TOKYO, JAPAN', 
    'TAOYUAN, TAIWAN', 'TANJUNG PELEPAS, MALAYSIA', 'TAIPEI, TAIWAN', 'TAICHUNG, TAIWAN', 'SURABAYA, INDONESIA', 'SINGAPORE', 
    'SIHANOUKVILLE, CAMBODIA', 'SHIMIZU, JAPAN', 'SEMARANG, INDONESIA', 'QUI NHON, VIETNAM', 'PORT KLANG, MALAYSIA', 
    'PENANG, MALAYSIA', 'PASIR GUDANG, MALAYSIA', 'PALEMBANG, INDONESIA', 'OSAKA, JAPAN', 'NHAVA SHEVA, INDIA', 
    'NAGOYA, JAPAN', 'MUNDRA, INDIA', 'MOJI, JAPAN', 'MANILA, PHILIPPINES', 'MANILA NORTH HARBOUR', 'LAT KRABANG, THAILAND', 
    'LAEM CHABANG, THAILAND', 'KOLKATA(EX CALCUTTA), INDIA', 'KOBE, JAPAN', 'KEELUNG, TAIWAN', 'KARACHI, PAKISTAN', 
    'KAOHSIUNG, TAIWAN', 'JAKARTA, INDONESIA', 'HOCHIMINH CITY, VIETNAM', 'HAKATA, JAPAN', 'HAIPHONG, VIETNAM', 
    'DAVAO, PHILIPPINES', 'DANANG, VIETNAM', 'COLOMBO, SRI LANKA', 'COCHIN, INDIA', 'CHATTOGRAM, BANGLADESH', 
    'CHENNAI, INDIA', 'CEBU, PHILIPPINES', 'CAI MEP, VIETNAM', 'BUSAN, KOREA', 'BELAWAN, INDONESIA', 'BATAM, INDONESIA', 
    'BANGKOK, THAILAND', 'PANJANG, INDONESIA', 'PIPAVAV (VICTOR) PORT, INDIA', 'HAZIRA, INDIA', 'KATTUPALLI, INDIA'
]

destination_ports = [
    'LAX/LGB', 'OAKLAND, CA', 'PORTLAND, OR', 'SEATTLE, WA', 'TACOMA, WA', 'BALTIMORE, MD', 'BOSTON, MA', 'CHARLESTON, SC', 
    'HOUSTON, TX', 'JACKSONVILLE, FL', 'MIAMI, FL', 'NEW ORLEANS, LA', 'NEW YORK, NY', 'PHILADELPHIA, PA', 
    'PORT EVERGLADES, FL', 'SAVANNAH, GA', 'TAMPA, FL', 'WILMINGTON, NC', 'ATLANTA, GA', 'BIRMINGHAM, AL', 'BUFFALO, NY', 
    'CHARLOTTE, NC', 'CHATSWORTH, GA', 'CHICAGO, IL', 'CHIPPEWA FALLS, WI', 'CINCINNATI, OH', 'CLEVELAND, OH', 
    'COLUMBUS, OH', 'CRANDALL, GA', 'DALLAS, TX', 'DENVER, CO', 'DETROIT, MI', 'EAST ST.LOUIS, IL', 'EL PASO, TX', 
    'GREENSBORO, NC', 'HUNTSVILLE, AL', 'INDIANAPOLIS, IN', 'KANSAS CITY, MO', 'LOUISVILLE, KY', 'MEMPHIS, TN', 
    'MINNEAPOLIS, MN', 'NASHVILLE, TN', 'OMAHA, NE', 'PHOENIX, AZ', 'PITTSBURGH, PA', 'RICHMOND, VA', 'SALT LAKE CITY, UT', 
    'SAN ANTONIO, TX', 'SANTA TERESA, NM', 'ST. LOUIS, MO', 'ST. PAUL, MN', 'WORCESTER, MA'
]

# Streamlit UI
st.title("Shipping Rates Query")
origin_select = st.multiselect("Select Origin Ports", origin_ports)
destination_select = st.multiselect("Select Destination Ports", destination_ports)
carrier_select = st.multiselect("Select Carrier", carrier_options)

date_select = st.multiselect("Select Expiring Dates", sorted(df["Expiring_Date"].dropna().unique()))

filtered_data = df[
    (df['POL'].isin(origin_select)) &
    (df['Destination'].isin(destination_select)) &
    (df['Carrier'].isin(carrier_select)) &
    (df["Expiring_Date"].isin(date_select))
]

trucking_fee = 0
if table_type == "Port to Door":
    trucking_fee = st.sidebar.number_input("Trucking Fee (USD)", min_value=0.0, step=10.0)

if origin_select and destination_select and carrier_select:
    routes = list(product(origin_select, destination_select, carrier_select))
    routes = [(o.upper(), d.upper(), c.upper()) for o,d,c in routes]
    st.markdown(f"### ğŸ§¾ å…±ç”Ÿæˆ {len(routes)} æ¡çº¿è·¯ï¼š")

    fixed_fields = {
        "ISF": 25,
        "Handling": 50,
        "Customs Clearance": 80,
        "Duty": "AT COST",
        "20' - CTF/PP": 48,
        "40' - CTF/PP": 95,
        "Chassis ($50/DAY) - min. 2 days": 100,
        "Trucking Fee": trucking_fee
    }

    combined_data = []

    for origin, destination, carrier in routes:
        found = False
        reasons = set()

        for table in table_names:
            df = load_table(table)
            if not {"POL","Destination","Carrier"}.issubset(df.columns):
                continue
            for c in ["POL","Destination","Carrier"]:
                df[c] = df[c].astype(str).str.strip().str.upper()

            m = df[(df["POL"]==origin) &
                   (df["Destination"]==destination) &
                   (df["Carrier"]==carrier)].copy()

            if not m.empty:
                for col, val in fixed_fields.items():
                    m.loc[:, col] = val
                m["20' - ALL IN"] = (m["GP20"] + fixed_fields["ISF"] +
                                     fixed_fields["Handling"] + fixed_fields["Customs Clearance"])
                m["40' or HC - ALL IN"] = (m["GP40"] + fixed_fields["ISF"] +
                                           fixed_fields["Handling"] + fixed_fields["Customs Clearance"])
                if table_type == "Port to Door":
                    m["20' - ALL IN"] += (fixed_fields["Trucking Fee"] +
                                          fixed_fields["20' - CTF/PP"] +
                                          fixed_fields["Chassis ($50/DAY) - min. 2 days"])
                    m["40' or HC - ALL IN"] += (fixed_fields["Trucking Fee"] +
                                                fixed_fields["40' - CTF/PP"] +
                                                fixed_fields["Chassis ($50/DAY) - min. 2 days"])
                m.loc[:, "è¡¨æ ¼ç±»å‹"] = table_type
                m.loc[:, "æ¥æºè¡¨"] = table
                combined_data.append(m)
                found = True
            else:
                if origin not in df["POL"].unique(): reasons.add(f"ç¼ºPOL: {origin}")
                if destination not in df["Destination"].unique(): reasons.add(f"ç¼ºDestination: {destination}")
                if carrier not in df["Carrier"].unique(): reasons.add(f"ç¼ºCarrier: {carrier}")

        if not found:
            print(f"âŒ æœªåŒ¹é…: {origin} â†’ {destination} ï½œ {carrier} ï½œ åŸå› : {'ï¼Œ'.join(sorted(reasons))}")


    if combined_data:
        total_df = pd.concat(combined_data, ignore_index=True)
        total_df["ISF"] = 25
        total_df["Handling"] = 50
        total_df["Customs Clearance"] = 80
        total_df["Duty"] = "AT COST"

        def is_integer_string(x):
            try:
                return float(x).is_integer()
            except:
                return False

        if "T_T_TO_POD" in total_df.columns:
            total_df["T_T_TO_POD"] = total_df["T_T_TO_POD"].apply(
                lambda x: f"{int(float(x))}-{int(float(x))+3} DAYS"
                if pd.notnull(x) and is_integer_string(x)
                else x
            )

        st.sidebar.markdown("### ğŸ’² GP20 / GP40 è°ƒæ•´")
        gp20_adjust = st.sidebar.number_input("è°ƒæ•´ GP20ï¼ˆå•ä½ï¼šç¾å…ƒï¼Œå¯ä¸ºè´Ÿæ•°ï¼‰", value=0.0, step=10.0)
        gp40_adjust = st.sidebar.number_input("è°ƒæ•´ GP40ï¼ˆå•ä½ï¼šç¾å…ƒï¼Œå¯ä¸ºè´Ÿæ•°ï¼‰", value=0.0, step=10.0)

        if 'GP20' in total_df.columns:
            total_df['GP20'] = total_df['GP20'] + gp20_adjust
        if 'GP40' in total_df.columns:
            total_df['GP40'] = total_df['GP40'] + gp40_adjust

        port_cols = ["POL", "Destination", "Carrier", "T_T_TO_POD",
                     "GP20", "GP40", "ISF", "Handling", "Customs Clearance", "Duty",
                     "20' - ALL IN", "40' or HC - ALL IN", "COMM", "COMM_DETAILS", "Expiring_Date", "æ¥æºè¡¨"]
        door_cols = ["POL", "Destination", "Carrier", "T_T_TO_POD", "GP20", "GP40", "ISF", "Handling", "Customs Clearance", "Duty", "Trucking Fee", "20' - CTF/PP", "40' - CTF/PP", "Chassis ($50/DAY) - min. 2 days", "20' - ALL IN", "40' or HC - ALL IN", "COMM", "COMM_DETAILS", "Expiring_Date", "æ¥æºè¡¨"]

        display_cols = door_cols if table_type == "Port to Door" else port_cols

        st.markdown("### ğŸ“Š åˆå¹¶åçš„æ€»è¡¨ï¼š")

        keyword = st.sidebar.text_input("è¯·è¾“å…¥å…³é”®è¯ï¼ˆç”¨äºè¿‡æ»¤remark/COMM/COMM_DETAILSï¼‰")
        filter_action = st.sidebar.radio(
            "é€‰æ‹©ç­›é€‰æ–¹å¼ï¼š",
            ("ä¸è¿‡æ»¤", "åªä¿ç•™åŒ…å«å…³é”®è¯çš„ç­æ¬¡", "å‰”é™¤åŒ…å«å…³é”®è¯çš„ç­æ¬¡")
        )
        max_shown = st.sidebar.number_input("æ¯æ¡çº¿è·¯æœ€å¤šåˆ—å‡ºå‡ æ¡æœ€ä¾¿å®œçš„ç­æ¬¡ï¼Ÿ", min_value=1, step=1, value=5)

        selected_rows = []
        col_20_all_in = "20' - ALL IN"

        grouped = total_df.groupby(["POL", "Destination"])

        for (pol, destination), group in grouped:
            group = group.sort_values(by="GP20", ascending=True)

            if keyword and filter_action != "ä¸è¿‡æ»¤":
                contains_keyword = group[['remark', 'COMM', 'COMM_DETAILS']].apply(
                    lambda x: x.astype(str).str.contains(keyword, case=False, na=False)
                ).any(axis=1)
                if filter_action == "åªä¿ç•™åŒ…å«å…³é”®è¯çš„ç­æ¬¡":
                    group = group[contains_keyword]
                elif filter_action == "å‰”é™¤åŒ…å«å…³é”®è¯çš„ç­æ¬¡":
                    group = group[~contains_keyword]

            if not group.empty:
                with st.expander(f"{pol} â†’ {destination}"):
                    selected_in_group = []
                    carrier_group = group.groupby("Carrier")

                    for carrier, carrier_df in carrier_group:
                        include = st.checkbox(f"âœ” åŒ…å« {carrier}", value=True, key=f"include_{pol}_{destination}_{carrier}")
                        if include:
                            carrier_df_sorted = carrier_df.sort_values(by="GP20", ascending=True)
                            selected_idx = st.radio(
                                f"{carrier} ç­æ¬¡é€‰æ‹©",
                                options=list(range(len(carrier_df_sorted))),
                                format_func=lambda idx: (
                                    f"20å°º {carrier_df_sorted.iloc[idx].get('GP20', 'æ— ')}ç¾å…ƒ ï½œ "
                                    f"40å°º {carrier_df_sorted.iloc[idx].get('GP40', 'æ— ')}ç¾å…ƒ ï½œ "
                                    f"å¤‡æ³¨: {carrier_df_sorted.iloc[idx].get('remark', 'æ— ')} ï½œ "
                                    f"COMM: {carrier_df_sorted.iloc[idx].get('COMM', 'æ— ')} ï½œ "
                                    f"COMM_DETAILS: {carrier_df_sorted.iloc[idx].get('COMM_DETAILS', 'æ— ')}"
                                ),
                                key=f"{pol}_{destination}_{carrier}"
                            )
                            selected_in_group.append(carrier_df_sorted.iloc[selected_idx])

                    if selected_in_group:
                        selected_df = pd.DataFrame(selected_in_group)
                        selected_df = selected_df.sort_values(by="GP40", ascending=True).head(max_shown)
                        selected_rows.extend(selected_df.to_dict("records"))

        final_selected_df = pd.DataFrame(selected_rows)
        final_selected_df = final_selected_df.reindex(columns=display_cols)

        if table_type == "Port to Port":
            final_selected_df.columns = [
                "ORIGIN", "DESTINATION", "Carrier", "Transit time (port to port)", "20'", "40' or HC", "ISF", "Handling", "Customs Clearance", "Duty", "20' - ALL IN", "40' or HC - ALL IN", "COMM", "COMM_DETAILS", "Expiring_Date", "æ¥æºè¡¨"
            ]
        else:
            final_selected_df.columns = [
                "ORIGIN", "DESTINATION", "Carrier", "Transit time (port to port)", "20'", "40' or HC", "ISF", "Handling", "Customs Clearance", "Duty", "Trucking Fee", "20' - CTF/PP", "40' - CTF/PP", "Chassis ($50/DAY) - min. 2 days", "20' - ALL IN", "40' or HC - ALL IN", "COMM", "COMM_DETAILS", "Expiring_Date", "æ¥æºè¡¨"
            ]

        st.markdown("### âœ… æœ€ç»ˆé€‰æ‹©çš„ç­æ¬¡åˆ—è¡¨ï¼š")
        st.dataframe(final_selected_df)

        csv = final_selected_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è½½æœ€ç»ˆé€‰æ‹©åçš„æ€»è¡¨ CSV", csv, "final_selected_routes.csv", "text/csv")
